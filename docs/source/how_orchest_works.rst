How Orchest works
=================

Orchest runs as a collection of Docker containers and stores a global configuration file. The
location for this config is :code:`~/.config/orchest/config.json`.

Orchest is powered by your filesystem. Upon launching, Orchest will mount the
:code:`orchest/userdir/` directory, where :code:`orchest/` is the install directory from GitHub,
into the docker containers. Inside the :code:`userdir/` Orchest will store all your scripts that make
up the pipeline, for example :code:`.ipynb` and :code:`.py` files. Additionally the following files
will be stored inside the :code:`.orchest/` directory at the pipeline level (and thus *for each
pipeline*):

* The :ref:`Orchest SDK` stores step outputs in the :code:`.orchest/data/` directory to pass data
  between pipeline steps (in the case where :meth:`orchest.transfer.output_to_disk` is used).
* Logs are stored in :code:`.orchest/logs/` to show STDOUT output from scripts in the pipeline view.
* An autogenerated :code:`.orchest/pipeline.json` file that defines the properties of the pipeline and its
  steps.  This includes: execution order, names, images, etc. Orchest needs this pipeline definition
  file to work.

Giving a directory structure similar to the following:

.. code-block:: bash

    .
    ├── preprocessing.ipynb
    ├── .ipynb_checkpoints/
    ├── .orchest
    │   ├── data/
    │   ├── logs/
    │   └── pipeline.json
    └── model-training.ipynb


Installing additional packages
------------------------------

Orchest runs all your individual pipeline steps (e.g. :code:`.ipynb` or :code:`.R` scripts) in
containers. The default images are based on the |jupyter_stack_link| and come with a number of
|pre_installed_link|.

To install additional packages or to run other terminal commands inside the base image, we support
custom *Images*. We essentially create a new image by running your script inside the selected base
image.

1. Simply go to *Images* in the left menu pane.
2. Select the base image. This image will be extended with your custom script. 
3. Click the "+" sign to add a commit to the base image. The commit represents the changes of your
   script.
4. Choose a *Commit name*.
5. Install additional packages, e.g. :code:`pip install tensorflow` or :code:`sudo apt install vim`.

.. |jupyter_stack_link| raw:: html

  <a href="https://jupyter-docker-stacks.readthedocs.io/en/latest/"
  target="_blank">Jupyter Docker Stacks</a>

.. |pre_installed_link| raw:: html

   <a
   href="https://jupyter-docker-stacks.readthedocs.io/en/latest/using/selecting.html"
   target="_nlank">pre-installed packages</a>

.. warning::
   Do not install packages by running :code:`!pip install <package-name>` inside your
   Jupyter Notebook. This causes the package to be installed every time you run the pipeline
   step. It is not saved in the environment as containers are stateless!
